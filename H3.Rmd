---
title: "Math523 H3"
author: "Li Zha"
date: "3/8/2019"
output: 
  pdf_document:
    latex_engine: xelatex

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


A9
(a)
```{r bin for Ten}
library(catdata)
data(foodstamp)
LMI <- log(foodstamp[,4]+1)
foodstamp <- cbind.data.frame(foodstamp,LMI) 
attach(foodstamp)

#For fixed Ten=0
df_TEN0<-subset(foodstamp,TEN==0)

# binning width into 10 categories
ncat<-10
bins<-cut(df_TEN0$LMI,quantile(df_TEN0$LMI,prob=c(0:ncat)/ncat),include.lowest=T)
par(mfrow=c(1,2))
counts<- split(df_TEN0$y,bins)
View(foodstamp)
logits_0 <- as.numeric(lapply(counts,FUN=function(x){log((sum(x)+0.5)/(length(x)-sum(x)+0.5))}))
props_0 <- as.numeric(lapply(counts,FUN=function(x){sum(x)/length(x)}))

LMI_TEN0.means <- as.numeric(lapply(split(df_TEN0$LMI,bins),mean))


#For fixed Ten=1
ncat<-10
df_TEN1<-subset(foodstamp,TEN==1)
bins<-cut(df_TEN1$LMI,quantile(df_TEN1$LMI,prob=c(0:ncat)/ncat),include.lowest=T)
par(mfrow=c(1,2))
counts<- split(df_TEN1$y,bins)

logits_1 <- as.numeric(lapply(counts,FUN=function(x){log((sum(x)+0.5)/(length(x)-sum(x)+0.5))}))
props_1 <- as.numeric(lapply(counts,FUN=function(x){sum(x)/length(x)}))

LMI_TEN1.means <- as.numeric(lapply(split(df_TEN1$LMI,bins),mean))

plot(LMI_TEN0.means,logits_0,pch=20,main="logits for TEN",ylab="logits",cex=0.5)
points(LMI_TEN1.means,logits_1,col="red")

plot(LMI_TEN0.means,props_0,pch=20,main="props for TEN",ylab="props",cex=0.5)
points(LMI_TEN1.means,props_1,col="red")

```
Depending on the level of TEN, I chose 10 bins using quantiles of LMI.
Clearly, the logits is a suitable link function for modeling on the data set since the logit link predict a similar pattern as the real value for both levels of TEN. 

For both TEN=0 and TEN=1, there is a slightyly decreasing trend on the proportion of those receiving foodstamp changes with the increasing of LMI. Thus, we may consider the factor TEN as a predictor in the model. 


```{r bin for SUP}
df_SUP1<-subset(foodstamp,SUP==1)

bins<-cut(df_SUP1$LMI,quantile(df_SUP1$LMI,prob=c(0:ncat)/ncat),include.lowest=T)
par(mfrow=c(1,2))
counts<- split(df_SUP1$y,bins)

logits1 <- as.numeric(lapply(counts,FUN=function(x){log((sum(x)+0.5)/(length(x)-sum(x)+0.5))}))
props1 <- as.numeric(lapply(counts,FUN=function(x){sum(x)/length(x)}))

LMI.means1 <- as.numeric(lapply(split(df_SUP1$LMI,bins),mean))

#SUP==0
df_SUP0<-subset(foodstamp,SUP==0)

bins<-cut(df_SUP0$LMI,quantile(df_SUP0$LMI,prob=c(0:ncat)/ncat),include.lowest=T)
par(mfrow=c(1,2))
counts<- split(df_SUP0$y,bins)

logits0 <- as.numeric(lapply(counts,FUN=function(x){log((sum(x)+0.5)/(length(x)-sum(x)+0.5))}))
props0 <- as.numeric(lapply(counts,FUN=function(x){sum(x)/length(x)}))

LMI.means0 <- as.numeric(lapply(split(df_SUP0$LMI,bins),mean))

plot(LMI.means0,logits0,main="logits for SUP", ylab="logits",cex=0.5)
points(LMI.means1,logits1,cex=0.5,col='red')

plot(LMI.means0,props0,main="porps for SUP", ylab="proportions",cex=0.5)
points(LMI.means1,props1,cex=0.5,col='red')
```
Depending on the level of SUP, I chose 10 bins using quantiles of LMI.
From the plot, the logits might be a suitable link function for modeling on the data set since the logit link predicts a similar pattern as the real value particularly for SUP=0. 
For both SUP=0 and SUP=1, there is no significant trend on the proportion of those receiving foodstamp changes with the increasing of LMI. Thus, we may not consider the factor SUP as a key predictor in the model. 


(b)

We see that model m2 could be an adequate simplification of the full model.The p-value is larger than 0.5, which shows that the effect of the interaction on TEN:SUP:LMI is quite small. Thus, removing TEN:SUP:LMI is possible. 
```{r fit model} 
m.full<-glm(foodstamp$y~TEN*SUP*LMI,family = binomial)
summary(m.full)
m2<-update(m.full,~.-TEN:SUP:LMI)
anova(m2,m.full,test="Chi")
```

```{r 1}
m3<-update(m2,~.-SUP:LMI)
anova(m3,m2,test="Chi")
```

The p-value is still slightly large than 0.05, thus removing the interaction on SUP:LMI is possible. 

```{r 2}
m4<-update(m3,~.-TEN:LMI)
anova(m4,m3,test="Chi")
```

The p-value is still larger than 0.05, thus removing the interaction on TEN:LMI is possible. 
```{r 3}
m5<-update(m4,~.-TEN:SUP)
anova(m5,m4,test="Chi")

```

The p-value is still larger than 0.05, thus removing the interaction on TEN:SUP is possible. 

```{r 4}
m6<-update(m5,~.-LMI)
anova(m6,m5,test="Chi")
```

The p-value is still larger than 0.05, thus removing the LMI is possible. 
```{r 5}
m7=update(m6,~.-SUP)
anova(m7,m6,test="Chi")
```

The p-value is still larger than 0.05, thus removing the SUP is possible. 
```{r 6}
summary(m6)
summary(m7)

z <- seq(from=0.0,to=0.8,by=0.01)
par(mfrow=c(1,2))
plot(predict(m7,type="response"),residuals(m7,type="pearson")
,ylab="Pearson residual",xlab="pi.hat")
lines(z,-sqrt(z/(1-z)),col="red")
lines(z,sqrt((1-z)/z),col="blue")
plot(predict(m7,type="response"),residuals(m7,type="deviance")
,ylab="Deviance residual",xlab="pi.hat")
lines(z,-sqrt(-2*log(1-z)),col="red")
lines(z,sqrt(-2*log(z)),col="blue")
```

Here we have finalize our model to m7: one intercept and one factor TEN.The summary table shows that the p-value for TEN is significantly small than 0.05. The model tells us with each unit increase of LMI, the odds for receivinig the foodstamp decreases by a factor of e^${-2.1347}$.  

We saw that there is some difference in the two residual plots. The data is not spread randomly around the plot which means it may not be a suitable model. 

(c)
```{r ROC}
roc.curve <- function(y,pred){
  p <- seq(from=0,to=1,by=0.01)
  out <- matrix(ncol=2,nrow=length(p))
  for(i in 1:length(p)){
    y.hat <- as.numeric(pred>p[i])
    tmp <- cbind(y,y.hat)
    I1 <- as.numeric(y==1)
    I2 <- as.numeric(y.hat==1)
    a <- sum(I1*I2)
    b <- sum(I1*(1-I2))
    c <- sum((1-I1)*I2)
    d <- sum((1-I1)*(1-I2))
    sens <- a/(a+b)
 spec <- d/(c+d)
    out[i,1] <- 1-spec
    out[i,2] <- sens
  }
  out  
}

m1<-glm(foodstamp$y~LMI*TEN*SUP,family = binomial)
m2<-glm(foodstamp$y~LMI+TEN+SUP,family = binomial)
m3<-glm(foodstamp$y~TEN,family = binomial)
pred1 <- predict(m1,type="response")
pred2 <- predict(m2,type="response")
pred3 <- predict(m3,type="response")

roc.m1 <- roc.curve(foodstamp$y,pred1)
roc.m2 <- roc.curve(foodstamp$y,pred2)
roc.m3 <- roc.curve(foodstamp$y,pred3)
plot(roc.m1,type="l",xlab="x",ylab="y",main="ROC curves for foodstamp",col="red")
lines(roc.m2,col="blue")
lines(roc.m3,col="green")
```

The figure displays that the ROC curve for model m1 (red), m2(blue) and m3(green). We can see that m2：LMI+TEN+SUP has a much better predictive power, because the area underneath the ROC curve is bigger. 


(d)
```{r goodness of fit }
##grouped by LMI
model<-glm(foodstamp$y~TEN,family = binomial)
ncat<-10
bins= cut(foodstamp$LMI,quantile(foodstamp$LMI,prob=c(0:ncat)/ncat),include.lowest=T)
counts<- split(foodstamp$y,bins)
beta=model$coefficients

observed <- lapply(counts,FUN=function(x){c(sum(x),length(x)-sum(x))})
observed <- matrix(as.numeric(unlist(observed)),ncol=2,byrow=TRUE)
observed=observed+0.5
fitted <- lapply(counts,FUN=function(x){pi <- exp(beta[1]+x*beta[2])/(1+exp(beta[1]+x*beta[2])); c(sum(pi),sum(1-pi)) } )

fitted <- matrix(as.numeric(unlist(fitted)),ncol=2,byrow=TRUE)

X.2  <- sum(((observed-fitted)^2)/fitted)
G.2 <- 2*sum(observed*log(observed/fitted))

X.2
G.2
pchisq(X.2, df=8,lower.tail=FALSE)
pchisq(G.2, df=8,lower.tail=FALSE)

```

For the grouped form, because the response is binary, deviance cannot be used to test model fit. Instead, we chose 10 bins and test for $X^2$ or $G^2$ statistic. We both obtained a significant p-value from $X^2$ or $G^2$ that means we will reject the null hypothesis that model: Y~1+TEN is simple adequate in the model. Thus the fit of this model is not adequate. 

```{r for e}
foodstamp[5,]
foodstamp[66,]

foodstampnew<-rbind(foodstamp[1:4,],foodstamp[6:65,],foodstamp[67:150,])
Ten<-foodstampnew$TEN
Sup<-foodstampnew$SUP
Lmi<-foodstampnew$LMI

n_full<-glm(foodstampnew$y~Ten*Sup*Lmi,family = binomial)
summary(n_full)
m_1<-update(n_full,~.-Ten:Sup:Lmi)
anova(m_1,n_full,test = "Chi")
m_2<-update(m_1,~.-Sup:Lmi)
anova(m_2,m_1,test = "Chi")
m_3<-update(m_2,~.-Ten:Lmi)
anova(m_3,m_2,test = "Chi")
m_4<-update(m_3,~.-Ten:Sup)
anova(m_4,m_3,test = "Chi")
summary(m_4)
m_5<-update(m_4,~.-Sup)
anova(m_5,m_4,test = "Chi")

m.full$aic
m_1$aic
m_2$aic
m_3$aic
m_4$aic
m_5$aic
summary(m_5)
```

Observarions #5 is influential point because its predictors are all 0. Similarly, observation #66 is influential because INC is much larger than the range of other datapoints. 

After removing the observations #5 and #66, we found m_5: y ~ TEN + LMI is the best model compared with others. The model obtains the smallest AIC value, and all coefficients are much significant with p-values less than 0.05 than the the fitted model in part (b) before influential points removed.  


```{r diagnostic_e}
z <- seq(from=0.0,to=0.8,by=0.01)
par(mfrow=c(1,2))
plot(predict(m_5,type="response"),residuals(m_5,type="pearson")
,ylab="Pearson residual",xlab="pi.hat")
lines(z,-sqrt(z/(1-z)),col="red")
lines(z,sqrt((1-z)/z),col="blue")
plot(predict(m_5,type="response"),residuals(m_5,type="deviance")
,ylab="Deviance residual",xlab="pi.hat")
lines(z,-sqrt(-2*log(1-z)),col="red")
lines(z,sqrt(-2*log(z)),col="blue")

```

The plot of the residuals against the fitted values along with the graphs of the functions red and blue are shown below. The two residual plot show a slight difference on the increasing probability of success. We see that points are spread for two parts(Y=0,Y=1). 

```{r ROC_e}
preds <- predict(m_5,type="response")
roc.ms <- roc.curve(foodstampnew$y,preds)
plot(roc.m1,type="l",xlab="x",ylab="y",main="ROC curves for foodstamp",col="red")
lines(roc.m2,col="blue")
lines(roc.m3,col="green")
lines(roc.ms)
```

We can see that m_5：LMI+TEN has a much better predictive power, because the area underneath the ROC curve is the largest beyond other models. 


```{r GOF}
bins= cut(foodstampnew$LMI,quantile(foodstampnew$LMI,prob=c(0:ncat)/ncat),include.lowest=T)
counts<- split(foodstampnew$y,bins)
beta=m_5$coefficients

observed <- lapply(counts,FUN=function(x){c(sum(x),length(x)-sum(x))})
observed <- matrix(as.numeric(unlist(observed)),ncol=2,byrow=TRUE)
observed=observed+0.5

fitted_TEN0 <- lapply(split(subset(foodstampnew$LMI,Ten==0),bins),FUN=function(x){pi <- exp(beta[1]+x*beta[3])/(1+exp(beta[1]+x*beta[3])); c(sum(pi),sum(1-pi)) } )

fitted_TEN1 <- lapply(split(subset(foodstampnew$LMI,Ten==1),bins),FUN=function(x){pi <- exp(beta[1]+beta[2]+x*beta[3])/(1+exp(beta[1]+beta[2]+x*beta[3])); c(sum(pi),sum(1-pi)) } )

fitted_TEN0 <- matrix(as.numeric(unlist(fitted_TEN0)),ncol=2,byrow=TRUE)
fitted_TEN1 <- matrix(as.numeric(unlist(fitted_TEN1)),ncol=2,byrow=TRUE)
fitted=fitted_TEN0+fitted_TEN1

X.2  <- sum(((observed-fitted)^2)/fitted)
G.2 <- 2*sum(observed*log(observed/fitted))

X.2
G.2

pchisq(X.2, df=8,lower.tail=FALSE)
pchisq(G.2, df=8,lower.tail=FALSE)

```

From the test for $X^2$ or $G^2$ statistic, we both obtained a significant p-value from $X^2$ or $G^2$ that means we will reject the null hypothesis that model: Y~LMI+TEN is simple adequate in the model. Thus the fit of this model is not adequate. 

When the TENis fixed, one unit increase of LMI decreases the odds of participating in foodstamp by a factor of $e^{1.4044}$. For a fixed LMI, the change in tendancy to no tenancy decreases the odds of participating in foodstamp by a factor of $e^{2.1306}$. 

(f)

In this case, we are trying to predict whether an individual participate in federal food-stamp program (binary response) from factor predictors (SUP or TEN) and continuous variable(LMI) using logistic regression. We first get a model with one predictor TEN by anova test. However, by using ROC curves and the diagnostic plot, this model is fitted badly than the others. After we eliminated the two influential observations, we found a better model with TEN and LMI. Again, after checking through the deviance and ROC plot, we conclude that this model fitted much better than the first model, but it was not an adequate simplification of full model. In conclusion, we can conclude that the influential points are one important factors to consider before modeling. And based on the plots and deviance testing, we might consider to find other suitable link functions for modeling. 


